{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required files for Kaplan Meier By Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pickle\n",
    "import fnmatch\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\", palette=\"colorblind\", color_codes=True)\n",
    "\n",
    "from survive import datasets\n",
    "from survive import SurvivalData\n",
    "from survive import KaplanMeier, Breslow, NelsonAalen\n",
    "from sksurv.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from pprint import pprint\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_column',None)\n",
    "pd.set_option('display.max_rows',None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KM Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kaplan_meier_group_for_status(survival_type=\"OS\", years=1, save_to_csv_filename = \"None\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    This is the main Kaplan Meier Function to generate a chart and DF with an option to save the DF as csv. \n",
    "    \"\"\"\n",
    "    \n",
    "    #declare Variables:\n",
    "    output_dfs_list = []\n",
    "    y_features = list(['status', survival_type + \"_days\"])\n",
    "    groups = [\"group 1\", \"group 2\", \"group 3\"]\n",
    "    group_dict = { \n",
    "                \"group 1\": {\n",
    "                             \"stage\": ['stage 4'],\\\n",
    "                           },\\\n",
    "                \"group 2\": {\n",
    "                             'stage': ['dcis/lcis non-invasive'],\\\n",
    "                           },\\\n",
    "                \"group 3\": {\n",
    "                             \"stage\": ['stage 4','dcis/lcis non-invasive'],\\\n",
    "                           },\n",
    "                }\n",
    "    \n",
    "    # Building Base df_dict\n",
    "    listToDrop = ['NRIC','dob','Has Bills?','Side','Hospital','KKH','NCCS','SGH','END_OF_ENTRY']\n",
    "    clinical = kaplan_meier_group_dataSetting(listToDrop)\n",
    "\n",
    "    year_list = list([1,5,10])\n",
    "    df_dict = kaplan_meier_group_ComputeYears(clinical,year_list)\n",
    "    \n",
    "\n",
    "    model_data_dict = kaplan_meier_group_layeredData(df_dict, group_dict,y_features,years, survival_type)\n",
    "\n",
    "    # Build DF's for each group\n",
    "    for group in groups:\n",
    "        group_df = pd.DataFrame(model_data_dict[group])\n",
    "#         display(group_df.head())\n",
    "        temp_df = pd.DataFrame()\n",
    "        temp_df[\"status\"] = group_df[\"status\"].apply(lambda status: 0 if status == False else 1)\n",
    "        temp_df[\"time\"] = group_df[survival_type + \"_days\"].apply(lambda time: time/365.25)\n",
    "\n",
    "        #build KM object\n",
    "        surv = SurvivalData(time=\"time\", status=\"status\", data=temp_df)\n",
    "        km = KaplanMeier()\n",
    "        km.fit(surv)\n",
    "    \n",
    "        #Show KM df\n",
    "        temp_KM_df = kaplan_meier_group_to_df(km)\n",
    "        temp_KM_df[\"group_label\"] = group\n",
    "        output_dfs_list.append(temp_KM_df)\n",
    "        print(\"Generated df for \", group,  survival_type)\n",
    "        \n",
    "    output_df = pd.concat(output_dfs_list, ignore_index=True)\n",
    "    \n",
    "    #if csv filename given, save as filename else, end function\n",
    "    if save_to_csv_filename == \"None\":\n",
    "        #End of function\n",
    "        return output_df\n",
    "        \n",
    "    else: \n",
    "        output_df.to_csv(save_to_csv_filename)\n",
    "        return output_df\n",
    "        \n",
    "def generate_kaplan_meier_group_with_class(years=1, save_to_csv_filename=\"None\"):\n",
    "    \n",
    "    survival_types = [\"OS\", \"DFS\", \"CSS\"]\n",
    "    output_dfs_list = []\n",
    "    \n",
    "    for survival_type in survival_types:\n",
    "        temp_df = generate_kaplan_meier_group_for_status(survival_type=survival_type, years=years, save_to_csv_filename=\"None\")\n",
    "        temp_df[\"class_label\"] = survival_type\n",
    "        output_dfs_list.append(temp_df)\n",
    "        \n",
    "    output_df = pd.concat(output_dfs_list, ignore_index=True)\n",
    "#     display(output_df)\n",
    "    \n",
    "    if save_to_csv_filename == \"None\":\n",
    "        #End of function\n",
    "        return output_df\n",
    "        \n",
    "    else: \n",
    "        output_df.to_csv(save_to_csv_filename)\n",
    "        return output_df\n",
    "\n",
    "def kaplan_meier_group_to_df(KM_object):\n",
    "    \n",
    "    # Process the summary as string\n",
    "    \n",
    "    summary_lines_list = str(KM_object.summary).split(\"\\n\")\n",
    "    \n",
    "    header = [\"time\", \"events\", \"at_risk\",  \"estimate\",  \"std_error\",  \"95%_CI_lower\",  \"95%_CI_upper\"]\n",
    "    rows = summary_lines_list[6:]\n",
    "    \n",
    "    row_values = []\n",
    "    \n",
    "    for row in rows:\n",
    "        \n",
    "        elements = row.split(\" \")\n",
    "        tmp = []\n",
    "        for element in elements:\n",
    "            if element.isnumeric() or (\".\" in element):\n",
    "                tmp.append(element)\n",
    "                \n",
    "        row_values.append(tmp)\n",
    "        \n",
    "    #Build df\n",
    "    output_df = pd.DataFrame()\n",
    "    temp_df = pd.DataFrame(row_values, columns=header)\n",
    "    output_df[\"time\"] = temp_df[\"time\"]\n",
    "    output_df[\"estimate\"] = temp_df[\"estimate\"]\n",
    "    output_df[\"lower\"] = temp_df[\"95%_CI_lower\"]\n",
    "    output_df[\"upper\"] = temp_df[\"95%_CI_upper\"]\n",
    "                \n",
    "    return output_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaplan_meier_group_drop_by_index(X,indexes):\n",
    "    \"\"\"\n",
    "    helper function to drop rows of dataframe and return new dataframe without those rows with indexes resetted\n",
    "    \"\"\"\n",
    "    X = X.drop(indexes)\n",
    "    X = X.reset_index().drop(columns=\"index\")\n",
    "    return(X)\n",
    "\n",
    "def kaplan_meier_group_dataSetting(dropCol,FILE_FOLDER = \"C:\\\\SMU_v2\\\\\"):\n",
    "    '''\n",
    "    function to read the pkl from from datasource\n",
    "        1. Remove dx_date that is NULL.\n",
    "        2. Drop all rows where crucial fields for X_features are NULL.\n",
    "        3. Convert Date columns into datetime format\n",
    "        4. Derive OS, CSS, DFS days based on dx_date\n",
    "        5. Create status column to indicate if the patient is dead or alive base on if death_age exists\n",
    "    '''\n",
    "    df = pd.read_pickle(FILE_FOLDER + \"clinical_output.pkl\").reset_index().drop(columns=\"index\")\n",
    "    to_drop = df[df['dx_date']==\"NA\"].index\n",
    "    df = kaplan_meier_group_drop_by_index(df,to_drop)\n",
    "\n",
    "    df.drop(columns=dropCol,inplace = True)\n",
    "\n",
    "    # drop all rows where dates are null\n",
    "    df.dropna(axis=0,\\\n",
    "                    subset=['Date_for_DFS','Date_for_OS','Date_for_CSS','dx_date','Age_@_Dx'],\\\n",
    "                    inplace=True)\n",
    "    \n",
    "    # convert all datetime in dataframe into dateime format for processing\n",
    "    df[\"Date_for_DFS\"] = pd.to_datetime(df[\"Date_for_DFS\"])\n",
    "    df[\"Date_for_OS\"] = pd.to_datetime(df[\"Date_for_OS\"])\n",
    "    df[\"Date_for_CSS\"] = pd.to_datetime(df[\"Date_for_CSS\"])\n",
    "    df[\"dx_date\"] = pd.to_datetime(df[\"dx_date\"])\n",
    "    df['last_seen']= pd.to_datetime(df[\"dx_date\"])\n",
    "    df['dob']= pd.to_datetime(df[\"dx_date\"])\n",
    "\n",
    "    # calculate in days\n",
    "    df[\"DFS_days\"] = (df[\"Date_for_DFS\"] - df['dx_date'] )/np.timedelta64(1, 'D')\n",
    "    df[\"OS_days\"] = (df[\"Date_for_OS\"] - df['dx_date'] )/np.timedelta64(1, 'D')\n",
    "    df[\"CSS_days\"] = (df[\"Date_for_CSS\"] - df['dx_date'] )/np.timedelta64(1, 'D')\n",
    "\n",
    "    # alive or dead\n",
    "    df['status'] = np.where(df['Count_as_OS'] == \"dead\", False, True)\n",
    "\n",
    "    return df\n",
    "\n",
    "def kaplan_meier_group_ComputeYears(df, Year_list):\n",
    "    '''\n",
    "    Create a list to contain df for different years of survival\n",
    "    The df will filter those patient that has deceased or days of survival longer than the defined years.\n",
    "    '''\n",
    "\n",
    "    df_dict = {}\n",
    "\n",
    "    for i in Year_list:\n",
    "        tmp = {}\n",
    "        for x in list([\"DFS\", \"CSS\", \"OS\"]):\n",
    "            df['{}_{}_years'.format(x, i)] = np.where(\n",
    "                                                      np.logical_or(df['death_age'] > 0,\\\n",
    "                                                      df['{}_days'.format(x)]/(365.25*i) >= i),\\\n",
    "                                                      True,False)\n",
    "            tmp[x] = df[df['{}_{}_years'.format(x, i)] == True]\n",
    "        df_dict['{}_years'.format(i)] = tmp\n",
    "    return df_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaplan_meier_group_settingXY(df, X_features, Y_features, OHE_LOCATION = \"C:\\\\SMU_v2\\\\OHE\\\\\", name=\"\"):\n",
    "    '''\n",
    "    This function returns the X and Y features need for model training\n",
    "        - The function also generates one pkl that contains the One Hot Encoder for new raw data \n",
    "    \n",
    "    X_features = features to use for X\n",
    "    Y_features = features to use for Y \n",
    "    YEAR = years of patient record interested\n",
    "    SYTPE = survival type (OS, DFS, CSS)\n",
    "    OHE_LOCATION = location to store the pkl file\n",
    "    '''\n",
    "    for i in  X_features:\n",
    "        if not (i in ['nodespos','Age_@_Dx','size_precise']):\n",
    "            df.loc[:,i] = df[i].astype(\"category\")\n",
    "        else:\n",
    "            df.loc[:,i] = df[i].astype(\"float32\")\n",
    "    \n",
    "    X = df[X_features]\n",
    "    Y = df[Y_features]\n",
    "\n",
    "    # Save enconder so that we can OHE new data\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(X)\n",
    "    \n",
    "    # OHE for probability\n",
    "    X = enc.transform(X)\n",
    "    with open(OHE_LOCATION + name + '_encoder.pickle', 'wb') as f:\n",
    "        pickle.dump(enc, f) \n",
    "                  \n",
    "    # convert Y to structured array\n",
    "    s = Y.dtypes\n",
    "    Y = np.array([tuple(x) for x in Y.values], dtype=list(zip(s.index, s)))\n",
    "   \n",
    "    return X, Y\n",
    "\n",
    "def kaplan_meier_group_layeredData(df, group_dict,y_features, YEAR, STYPE):\n",
    "    \n",
    "    '''\n",
    "        this function generates the dataframe required for specific groups we hope to analyze\n",
    "        there are total 3 different groups but group 3 consist of multiple subgroups which leads a total of 5\n",
    "        dataframe.\n",
    "        Group 1: patient with stage 4 cancer\n",
    "        Group 2: patient which unknown records or at initial diagnosis stage\n",
    "        Group 3: make up of patient that does not belong to the groups above\n",
    "    '''\n",
    "    model_data_dict = {}\n",
    "    TO_USE = df['{}_years'.format(YEAR)][STYPE]\n",
    "    \n",
    "    print(\"Overall initial size: {} \\n\".format(TO_USE.shape[0]))\n",
    "        \n",
    "    for key,value in group_dict.items():\n",
    "        TO_USE_COPY = TO_USE.copy()\n",
    "\n",
    "        tmp = {}\n",
    "    \n",
    "        if key != \"group 3\":\n",
    "            # for group 1 and group 2 select rows that contains either stage 4/non invasive in Stage\n",
    "            TO_USE_COPY = TO_USE_COPY.loc[TO_USE_COPY['Stage'] == group_dict[key]['stage'][0]]\n",
    "        else:\n",
    "            # for group 3 do not select rows that contains either stage 4 or non invasive in c_Staging or p_Staging\n",
    "            stage = np.logical_and(TO_USE_COPY['Stage'] != group_dict[key]['stage'][0],\\\n",
    "                                    TO_USE_COPY['Stage'] != group_dict[key]['stage'][1])\n",
    "            \n",
    "            TO_USE_COPY = TO_USE_COPY.loc[stage]\n",
    "        \n",
    "        tmp = TO_USE_COPY[y_features]\n",
    "\n",
    "    \n",
    "        model_data_dict[key] = tmp\n",
    "        \n",
    "        \n",
    "    return model_data_dict\n",
    "\n",
    "def kaplan_meier_group_loadOHE(df,OHE_LOCATION = \"C:\\\\SMU_v2\\\\OHE\\\\\", name=\"\"):\n",
    "    '''\n",
    "    load enconder to OHE new raw data for prediction\n",
    "    '''\n",
    "    with open( \"{}{}{}\".format(OHE_LOCATION, name, '_encoder.pickle'), 'rb') as f:\n",
    "        enc = pickle.load(f) \n",
    "    \n",
    "    #type case object to category\n",
    "    typeCastList = list(df.select_dtypes(include=[object]).columns)\n",
    "    df[typeCastList] = df[typeCastList].astype(\"category\")\n",
    "    OHE_New_Data = enc.transform(df)\n",
    "    \n",
    "    return OHE_New_Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaplan Meier Analysis By Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = generate_kaplan_meier_group_with_class(years=1, save_to_csv_filename=\"None\")\n",
    "display(output.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
